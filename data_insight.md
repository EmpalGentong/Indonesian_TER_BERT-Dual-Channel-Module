### data sudah dilakukan proses lexical diantarnya:
- menghapus duplikat
- lower casing
- hastag removal
- unused information(tag, emoticon, simbol non emotions)

### proses yang akan dicoba selanjutnya:
- Tokenization* 
- Stopword Removal*
- Phrase Detection*
- Stemming*